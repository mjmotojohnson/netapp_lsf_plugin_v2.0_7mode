[MAIN]

; The directory containing the XML files outputted by the NetApp ontapmon.py
; performance monitoring script.
;ontap_xml_data_directory = /mnt/lsf/ontapmon_data
ontap_xml_data_directory = .

; The directory path containing the LSF job report text files outputted by
; the NetApp LSF compute agent ELIM script.
;lsf_job_report_directory = /mnt/lsf/netapp_job_reports
lsf_job_report_directory = .

; The directory path where hot job report text files will be outputted.
hot_job_report_directory = .

; How often (in seconds) that this script should check the ONTAP performance
; XML files to look for performance problems and send a report if any are
; found.
file_check_interval = 30

; If performance problems are found, this script can execute a command to
; perform some action. By default, this script will call netapp_lsf_hot_job_email.py,
; which will send the report data to an email address. A text report file
; is written detailing performance problems and the path to this file is
; appended to the command below as an argument to the called script.
command_to_run = python netapp_lsf_hot_job_email.py

; For each performance problem, this script will look for the LSF jobs that
; have performed the most recent operations against the impacted volume.
; These top jobs are included in the performance problem report. This
; parameter controls how many jobs should be included for each performance
; problem.
num_top_jobs_to_report = 3

; Controls whether the text report file detailing the performance problems
; should be deleted by this script after the command_to_run has finished
; executing. If false, the report file will not be deleted, allowing it
; to be moved or handled manually or by the called command.
delete_report_after_command = false


; Global thresholds. These thresholds apply in the case that no specific
; target threshold is configured for the controller or volume in question.
;
; Setting a threshold to a value of -1 disables it, causing no checks to
; be performed against that threshold.
[GLOBAL_THRESHOLDS]

; Maximum allowed disk busy percent (0-100) for any disk on an aggregate.
Max_DiskBusy		= 50

; Maximum allowed non-exempt domain utilization (0-100). The non-exempt
; domains are: raid, target, kahuna, storage, nwk_legacy, cifs
Max_NEDomain		= 75

; Maximum allowed average volume latency (in ms).
Max_AvgVolLatency	= 25

; Minimum number of available files on volumes.
Min_AvailFiles		= 1000

; Minimum available size on volumes (in MB).
Min_AvailSize		= 1000



; Target thresholds are configured on a controller- or volume-level
; basis, overriding the global thresholds for those storage objects.
;
; Setting a threshold to a value of -1 disables it, causing no checks to
; be performed against that threshold.
[TARGET_THRESHOLDS]

; These thresholds are configured in the following form:
; 
; For a controller-level threshold:
; fas6280c-svl				Max_AvgVolLatency	= 50
; For a volume-level threshold:
; fas6280c-svl:/vol/volNFS	Max_AvgVolLatency	= 100
; 
; Replace the controller, volume, threshold name and thresholds value
; to configure thresholds.

; Some thresholds apply only at the controller-level, like Max_NEDomain.
; These should be set on the controller level only. Setting a
; controller-level threshold against a specific volume will have no
; effect. Max_DiskBusy can be set against specific volumes but should
; share the same value for all volumes in an aggregate.

; If both a controller-level threshold and a volume-level threshold
; exist, the volume-level threshold takes priority. For example, in
; the sample thresholds above, volNFS on controller fas6280c-svl will
; be tested against a Max_AvgVolLatency value of 100, since that is the
; more specific threshold. Other volumes on that controller (which
; don't have a specific volume-level threshold set) will be tested against
; the controller-level Max_AvgVolLatency value of 50.

fas6280c-svl11				Max_AvgVolLatency	= 15
fas6280c-svl11:/vol/nfsDS	Max_AvgVolLatency	= 20

fas6280c-svl11:/vol/nfsDS	Min_AvailFiles	= 40000000
